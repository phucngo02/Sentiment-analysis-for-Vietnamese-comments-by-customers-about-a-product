{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1PXTbHJBuR3mTBp01Cp2mNtKRd4QLyPNi","timestamp":1684775171513}],"gpuType":"T4","authorship_tag":"ABX9TyOtK3W5r9rvfaueWZV3OSTj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KeNoRSE0t2HX","executionInfo":{"status":"ok","timestamp":1684774672019,"user_tz":-420,"elapsed":7110,"user":{"displayName":"Nhân Nguyễn Thành","userId":"14305693631364031056"}},"outputId":"7cafd41f-2c3a-49a7-b713-c6322ae5a5ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["import os\n","import csv\n","import numpy as np\n","import re\n","import pandas as pd\n","import pyvi\n","from pyvi import ViTokenizer, ViPosTagger"],"metadata":{"id":"_y_EgeyiuPI4","executionInfo":{"status":"ok","timestamp":1684774672019,"user_tz":-420,"elapsed":3,"user":{"displayName":"Nhân Nguyễn Thành","userId":"14305693631364031056"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install pyvi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRt0oIy9xpi-","executionInfo":{"status":"ok","timestamp":1684774677054,"user_tz":-420,"elapsed":5037,"user":{"displayName":"Nhân Nguyễn Thành","userId":"14305693631364031056"}},"outputId":"8d567ea0-a891-4d39-e460-dba889ac7d51"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyvi in /usr/local/lib/python3.10/dist-packages (0.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pyvi) (1.2.2)\n","Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.10/dist-packages (from pyvi) (0.3.6)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.22.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (3.1.0)\n","Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (1.16.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.8.10)\n","Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (4.65.0)\n"]}]},{"cell_type":"code","source":["file_path = '/content/gdrive/MyDrive/IE403/sentiments_raw.txt'"],"metadata":{"id":"cjfKzNCNvPEQ","executionInfo":{"status":"ok","timestamp":1684774677054,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nhân Nguyễn Thành","userId":"14305693631364031056"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["with open(\"/content/gdrive/MyDrive/IE403/Stopword.txt\",'rb') as f:\n","    contents = f.read()\n","contents = contents.decode(\"utf-16\")\n","contents = contents.split(\"\\r\\n\")\n","stopword = set(contents)\n"," \n","def remove_stopwords(line):\n","    words = []\n","    for word in line.strip().split():\n","        if word not in stopword:\n","            words.append(word)\n","    return ' '.join(words)"],"metadata":{"id":"9eC_-GwiN8iy","executionInfo":{"status":"ok","timestamp":1684774677054,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nhân Nguyễn Thành","userId":"14305693631364031056"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def apply_teencode_transformations(sentence):\n","    code = ['ctrai', 'khôg', 'bme', 'cta', 'mih', 'mqh', 'cgai', 'nhữg', 'mng', 'svtn', 'r', 'qtam', 'thươg', 'qtâm', 'chug', 'trườg', 'thoy', 'đki', 'atsm', 'ạk', 'cv', 'vch', 'cùg', 'pn', 'pjt', 'thjk', 'keke', 'ktra', 'nek', 'cgái', 'nthe', 'chúg', 'kái', 'tìh', 'phòg', 'lòg', 'từg', 'rằg', 'sốg', 'thuj', 'thuơng', 'càg', 'đky', 'bằg', 'sviên', 'ák', 'đág', 'nvay', 'nhjeu', 'xg', 'zồi', 'trag', 'zữ', 'atrai', 'kte', 'độg', 'lmht', 'gắg', 'đzai', 'thgian', 'plz', 'đồg', 'btrai', 'nthê', 'hìhì', 'vọg', 'hihe', 'đôg', 'răg', 'thườg', 'tcảm', 'đứg', 'ksao', 'dz', 'hjxhjx', 'cmày', 'xuốg', 'nkư', 'lquan', 'tiếg', 'hajz', 'xih', 'hìh', 'thàh', 'ngke', 'dzậy', 'teencode', 'tnào', 'tưởg', 'ctrinh', 'phog', 'hôg', 'zìa', 'kũg', 'ntnao', 'trọg', 'nthế', 'năg', 'ngđó', 'lquen', 'riêg', 'ngag', 'hêhê', 'bnhiu', 'ngốk', 'kậu', 'highland', 'kqua', 'htrc', 'địh', 'gđình', 'giốg', 'csống', 'xug', 'zùi', 'bnhiêu', 'cbị', 'kòn', 'buôg', 'csong', 'chàg', 'chăg', 'ngàh', 'llac', 'nkưng', 'nắg', 'tíh', 'khoảg', 'thík', 'ngđo', 'ngkhác', 'thẳg', 'kảm', 'dàh', 'júp', 'lặg', 'vđê', 'bbè', 'bóg', 'dky', 'dòg', 'uốg', 'tyêu', 'snvv', 'đthoại', 'qhe', 'cviec', 'tượg', 'qà', 'thjc', 'nhưq', 'cđời', 'bthường', 'zà', 'đáh', 'xloi', 'zám', 'qtrọng', 'bìh', 'lzi', 'qhệ', 'đhbkhn', 'hajzz', 'kủa', 'lz', 'đhkhtn', 'đóg', 'cka', 'lgi', 'nvậy', 'qả', 'đkiện', 'nèk', 'tlai', 'bsĩ', 'hkì', 'đcsvn', 'vde', 'chta', 'òy', 'ltinh', 'ngyeu', 'đthoai', 'snghĩ', 'nặg', 'họk', 'dừg', 'hphúc', 'hiha', 'wtâm', 'thíck', 'chuện', 'lạh', 'fây', 'ntnày', 'lúk', 'haj', 'ngía', 'mớj', 'hsơ', 'ctraj', 'nyêu', 'điiiiiii', 'rồii', 'c', 'kih', 'kb', 'hixxx', 'dthương', 'nhiềuuu', 'ctrình', 'mìnk', 'mjh', 'ng', 'vc', 'uhm', 'thỳ', 'nyc', 'tks', 'nàg', 'thôii', 'đjên', 'bgái', 'vớii', 'xink', 'hđộng', 'đhọc', 'mk', 'bn', 'thik', 'cj', 'mn', 'nguoi', 'nógn', 'hok', 'ko', 'bik', 'vs', 'cx', 'mik', 'wtf', 'đc', 'cmt', 'ck', 'chk', 'ngta', 'gđ', 'oh', 'vk', 'ctác', 'sg', 'ae', 'ah', 'ạh', 'rì', 'ms', 'vn', 'nhaa', 'cũg', 'đag', 'ơiii', 'hic', 'ace', 'àk', 'uh', 'cmm', 'cmnr', 'ơiiii', 'hnay', 'ukm', 'tq', 'ctr', 'đii', 'nch', 'trieu', 'hahah', 'nta', 'ngèo', 'kêh', 'ak', 'ad', 'j', 'ny', 'dc', 'qc', 'baoh', 'zui', 'zẻ', 'tym', 'aye', 'eya', 'fb', 'insta', 'z', 'thich', 'vcl', 'đt', 'acc', 'lol', 'loz', 'lozz', 'trc', 'chs', 'đhs', 'qá', 'ntn', 'wá', 'zậy', 'zô', 'ytb', 'vđ', 'vchg', 'sml', 'xl', 'cmn', 'face', 'hjhj', 'vv', 'ns', 'iu', 'vcđ', 'in4', 'qq', 'sub', 'kh', 'zạ', 'oy', 'jo', 'clmm', 'bsvv', 'troai', 'wa', 'hjx', 'e', 'ik', 'ji', 'ce', 'lm', 'đz', 'sr', 'ib', 'hoy', 'đbh', 'k', 'vd', 'a', 'cũng z', 'z là', 'unf', 'my fen', 'fen', 'cty', 'on lai', 'u hai ba', 'kô', 'đtqg', 'hqua', 'xog', 'uh', 'uk', 'nhoé', 'biet', 'quí', 'stk', 'hong kong', 'đươc', 'nghành', 'nvqs', 'ngừoi', 'trog', 'tgian', 'biêt', 'fải', 'nguời', 'tđn', 'bth', 'vcđ', 'tgdd', 'khg', 'nhưg', 'thpt', 'thằg', 'đuợc', 'dc', 'đc', 'ah', 'àh', 'ku', 'thým', 'onl', 'zô', 'zú', 'cmnd', 'sđt', 'klq']\n","    chuanhoa = ['con trai', 'không', 'bố mẹ', 'chúng ta', 'mình', 'mối quan hệ', 'con gái', 'những', 'mọi người', 'sinh viên tình nguyện', 'rồi', 'quan tâm', 'thương', 'quan tâm', 'chung', 'trường', 'thôi', 'đăng ký', 'ảo tưởng sức mạnh', 'ạ', 'công việc', 'vãi chưởng', 'cùng', 'bạn', 'biết', 'thích', 'ce ce', 'kiểm tra', 'nè', 'con gái', 'như thế', 'chúng', 'cái', 'tình', 'phòng', 'lòng', 'từng', 'rằng', 'sống', 'thôi', 'thương', 'càng', 'đăng ký', 'bằng', 'sinh viên', 'á', 'đáng', 'như vậy', 'nhiều', 'xuống', 'rồi', 'trang', 'dữ', 'anh trai', 'kinh tế', 'động', 'liên minh huyền thoại', 'gắng', 'đẹp trai', 'thời gian', 'pờ ly', 'đồng', 'bạn trai', 'như thế', 'hì hì', 'vọng', 'hi he', 'đông', 'răng', 'thường', 'tình cảm', 'đứng', 'không sao', 'đẹp trai', 'hix hix', 'chúng mày', 'xuống', 'như', 'liên quan', 'tiếng', 'hai', 'xinh', 'hình', 'thành', 'nghe', 'dậy', 'tin cốt', 'thế nào', 'tưởng', 'chương trình', 'phong', 'không', 'gì', 'cũng', 'như thế nào', 'trọng', 'như thế', 'năng', 'người đó', 'làm quen', 'riêng', 'ngang', 'hê hê', 'bao nhiêu', 'ngốc', 'cậu', 'hai lừn', 'kết quả', 'hôm trước', 'định', 'gia đinh', 'giống', 'cuộc sống', 'xùng', 'rồi', 'bao nhiêu', 'chuẩn bị', 'còn', 'buông', 'cuộc sống', 'chàng', 'chăng', 'ngành', 'liên lạc', 'nhưng', 'nắng', 'tính', 'khoảng', 'thích', 'người đó', 'người khác', 'thẳng', 'cảm', 'dành', 'giúp', 'lặng', 'vấn đề', 'bạn bè', 'bóng', 'đăng ký', 'dòng', 'uống', 'tình yêu', 'sinh nhật vui vẻ', 'điện thoại', 'quan hệ', 'công việc', 'tượng', 'quà', 'thích', 'nhưng', 'cuộc đời', 'bình thường', 'già', 'đánh', 'xin lỗi', 'dám', 'quan trọng', 'bình', 'làm gì', 'quan hệ', 'đại học bách khoa hà nội', 'hai', 'của', 'làm gì', 'đại học khoa học tự nhiên', 'đóng', 'cha', 'làm gì', 'như vậy', 'quả', 'điều kiện', 'nè', 'tương lai', 'bác sĩ', 'học kỳ', 'đảng cộng sản việt nam', 'vấn đề', 'chúng ta', 'rồi', 'linh tinh', 'người yêu', 'điện thoại', 'suy nghĩ', 'nặng', 'học', 'dừng', 'hạnh phúc', 'hi ha', 'quan tâm', 'thích', 'chuyện', 'lạnh', 'phây', 'như thế này', 'lúc', 'hai', 'nghía', 'mới', 'hồ sơ', 'con trai', 'người yêu', 'đi', 'rồi', 'chị', 'kinh', 'kết bạn', 'hích', 'dễ thương', 'nhiều', 'chương trình', 'mình', 'mình', 'người', 'vợ chồng', 'ừm', 'thì', 'người yêu cũ', 'thanks', 'nàng', 'thôi', 'điên', 'bạn gái', 'với', 'xinh', 'hành động', 'đại học', 'mình', 'bạn', 'thích', 'chị', 'mọi người', 'người', 'nóng', 'không', 'không', 'biết', 'với', 'cũng', 'mình', 'what the fuck', 'được', 'comment', 'chồng', 'chồng', 'người ta', 'gia đình', 'ồ', 'vợ', 'công tác', 'sài gòn', 'anh em', 'à', 'ạ', 'gì', 'mới', 'việt nam', 'nha', 'cũng', 'đang', 'ơi', 'hích', 'anh chị em', 'à', 'ừ', 'con mẹ mày', 'con mẹ nó rồi', 'ơi', 'hôm nay', 'ừm', 'trung quốc', 'chương trình', 'đi', 'nói chuyện', 'triệu', 'ha ha', 'người ta', 'nghèo', 'kênh', 'à', 'admin', 'gì', 'người yêu', 'được', 'quảng cáo', 'bao giờ', 'vui', 'vẻ', 'tim', 'anh yêu em', 'em yêu anh', 'facebook', 'instagram', 'vậy', 'thích', 'vờ cờ lờ', 'điện thoại', 'account', 'lồn', 'lồn', 'lồn', 'trước', 'chẳng hiểu sao', 'đéo hiểu sao', 'quá', 'như thế nào', 'quá', 'vậy', 'vô', 'youtube', 'vãi đái', 'vãi chưởng', 'sấp mặt lờ', 'xin lỗi', 'con mẹ nó', 'facebook', 'hi hi', 'vui vẻ', 'nói', 'yêu', 'vãi cải đái', 'info', 'quằn què', 'subcribe', 'không', 'vậy', 'rồi', 'giờ', 'cái lồn mẹ mày', 'buổi sáng vui vẻ', 'trai', 'quá', 'hix', 'em', 'ý', 'gì', 'chị em', 'làm', 'đẹp giai', 'sorry', 'inbox', 'thôi', 'đéo bao giờ', 'không', 'ví dụ', 'anh', 'cũng vậy', 'vậy là', 'unfriend', 'my friend', 'friend', 'công ty', 'online', 'u23', 'không', 'đội tuyển quốc gia', 'hôm qua', 'xong', 'ừ', 'ừ', 'nhé', 'biết', 'quý', 'số tài khoản', 'hồng kông', 'được', 'ngành', 'nghĩa vụ quân sự', 'người', 'trong', 'thời gian', 'biết', 'phải', 'người', 'thế đéo nào', 'bình thường', 'vãi cả đái', 'thế giới di động', 'không', 'nhưng', 'trung học phổ thông', 'thằng', 'được', 'được', 'được', 'à', 'à', 'cu', 'thím', 'online', 'dô', 'vú', 'chứng minh nhân dân', 'số điện thoại', 'không liên quan']\n","    data = {\"code\" : code, \"chuanhoa\" : chuanhoa}\n","    teencode = pd.DataFrame(data)\n","    result = [x.strip() for x in sentence.split()]\n","    for i in range(0, len(result)):\n","        for j in range(0, len(teencode)):\n","            if (result[i] == teencode.at[j, \"code\"]):\n","                result[i] = teencode.at[j, \"chuanhoa\"]\n","    x = \" \".join(result)\n","    x.strip()\n","    return x"],"metadata":{"id":"z0QvAmq5TSn4","executionInfo":{"status":"ok","timestamp":1684774677055,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nhân Nguyễn Thành","userId":"14305693631364031056"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["file_path1 = file_path"],"metadata":{"id":"93GQ2RB8TxqY","executionInfo":{"status":"ok","timestamp":1684774677055,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nhân Nguyễn Thành","userId":"14305693631364031056"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def preprocess_text_file(file_path):\n","    normalized_lines = []\n","\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        reader = csv.reader(file, delimiter='\\t')\n","\n","        for row in reader:\n","            # Kiểm tra số lượng cột hợp lệ\n","            if len(row) != 5:\n","                print(f\"Ignored line due to invalid number of columns: {row}\")\n","                continue\n","\n","            comment = row[4]  # Lấy nội dung trong cột \"comment\"\n","\n","            # Loại bỏ các hàng chứa từ có 8 chữ cái trở lên\n","            words = comment.split()\n","            if any(len(word) >= 8 for word in words):\n","                continue\n","\n","            # Chuẩn hóa chữ hoa thành chữ thường\n","            normalized_comment = comment.lower()\n","\n","            row[4] = normalized_comment  # Cập nhật nội dung đã chuẩn hóa vào cột \"comment\"\n","\n","            normalized_line = '\\t'.join(row)  # Ghép các cột thành dòng đã chuẩn hóa\n","\n","            normalized_lines.append(normalized_line)  # Thêm dòng đã chuẩn hóa vào danh sách\n","\n","    # Xuất kết quả ra file csv\n","    csv_file_path = '/content/gdrive/MyDrive/IE403/data_normalized.csv'  # Đường dẫn đến file csv\n","    with open(csv_file_path, 'w', newline='', encoding='utf-8') as file:\n","        writer = csv.writer(file, delimiter='\\t')\n","        writer.writerows([line.split('\\t') for line in normalized_lines])\n","\n","    # Xuất kết quả ra file txt\n","    txt_file_path = '/content/gdrive/MyDrive/IE403/data_normalized.txt'  # Đường dẫn đến file txt\n","    np.savetxt(txt_file_path, normalized_lines, fmt='%s', delimiter='\\t')\n","\n","# Ví dụ sử dụng hàm preprocess_text_file với một file có cột \"comment\"\n","\n","preprocess_text_file(file_path1)\n"],"metadata":{"id":"4NpF_5UoTphx","executionInfo":{"status":"ok","timestamp":1684774677055,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nhân Nguyễn Thành","userId":"14305693631364031056"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["file_path1 = '/content/gdrive/MyDrive/IE403/data_normalized.txt'\n","def preprocess_text_file(file_path):\n","    normalized_lines = []\n","\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        reader = csv.reader(file, delimiter='\\t')\n","\n","        for row in reader:\n","            # Kiểm tra số lượng cột hợp lệ\n","            if len(row) != 5:\n","                print(f\"Ignored line due to invalid number of columns: {row}\")\n","                continue\n","\n","            comment = row[4]  # Lấy nội dung trong cột \"comment\"\n","\n","            # Xử lý clear teencode transformation\n","            normalized_comment = apply_teencode_transformations(comment)\n","            \n","            row[4] = normalized_comment  # Cập nhật nội dung đã chuẩn hóa vào cột \"comment\"\n","\n","            normalized_line = '\\t'.join(row)  # Ghép các cột thành dòng đã chuẩn hóa\n","\n","            normalized_lines.append(normalized_line)  # Thêm dòng đã chuẩn hóa vào danh sách\n","\n","    # Xuất kết quả ra file csv\n","    csv_file_path = '/content/gdrive/MyDrive/IE403/data_normalized.csv'  # Đường dẫn đến file csv\n","    with open(csv_file_path, 'w', newline='', encoding='utf-8') as file:\n","        writer = csv.writer(file, delimiter='\\t')\n","        writer.writerows([line.split('\\t') for line in normalized_lines])\n","\n","    # Xuất kết quả ra file txt\n","    txt_file_path = '/content/gdrive/MyDrive/IE403/data_normalized.txt'  # Đường dẫn đến file txt\n","    np.savetxt(txt_file_path, normalized_lines, fmt='%s', delimiter='\\t')\n","\n","# Ví dụ sử dụng hàm preprocess_text_file với một file có cột \"comment\"\n","preprocess_text_file(file_path1)"],"metadata":{"id":"svNKTl2kV0DR","executionInfo":{"status":"ok","timestamp":1684774870774,"user_tz":-420,"elapsed":193723,"user":{"displayName":"Nhân Nguyễn Thành","userId":"14305693631364031056"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["file_path1 = '/content/gdrive/MyDrive/IE403/data_normalized.txt'\n","def preprocess_text_file(file_path):\n","    normalized_lines = []\n","\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        reader = csv.reader(file, delimiter='\\t')\n","\n","        for row in reader:\n","            # Kiểm tra số lượng cột hợp lệ\n","            if len(row) != 5:\n","                print(f\"Ignored line due to invalid number of columns: {row}\")\n","                continue\n","\n","            comment = row[4]  # Lấy nội dung trong cột \"comment\"\n","\n","            # Loại bỏ stop word trong tiếng Việt\n","            normalized_comment = remove_stopwords(comment)\n","\n","            row[4] = normalized_comment  # Cập nhật nội dung đã chuẩn hóa vào cột \"comment\"\n","\n","            normalized_line = '\\t'.join(row)  # Ghép các cột thành dòng đã chuẩn hóa\n","\n","            normalized_lines.append(normalized_line)  # Thêm dòng đã chuẩn hóa vào danh sách\n","\n","    # Xuất kết quả ra file csv\n","    csv_file_path = '/content/gdrive/MyDrive/IE403/data_normalized.csv'  # Đường dẫn đến file csv\n","    with open(csv_file_path, 'w', newline='', encoding='utf-8') as file:\n","        writer = csv.writer(file, delimiter='\\t')\n","        writer.writerows([line.split('\\t') for line in normalized_lines])\n","\n","    # Xuất kết quả ra file txt\n","    txt_file_path = '/content/gdrive/MyDrive/IE403/data_normalized.txt'  # Đường dẫn đến file txt\n","    np.savetxt(txt_file_path, normalized_lines, fmt='%s', delimiter='\\t')\n","\n","# Ví dụ sử dụng hàm preprocess_text_file với một file có cột \"comment\"\n","preprocess_text_file(file_path1)"],"metadata":{"id":"LUCtPPyZT7yY","executionInfo":{"status":"ok","timestamp":1684774870775,"user_tz":-420,"elapsed":11,"user":{"displayName":"Nhân Nguyễn Thành","userId":"14305693631364031056"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["file_path1 = '/content/gdrive/MyDrive/IE403/data_normalized.txt'\n","def preprocess_text_file(file_path):\n","    normalized_lines = []\n","\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        reader = csv.reader(file, delimiter='\\t')\n","\n","        for row in reader:\n","            # Kiểm tra số lượng cột hợp lệ\n","            if len(row) != 5:\n","                print(f\"Ignored line due to invalid number of columns: {row}\")\n","                continue\n","\n","            comment = row[4]  # Lấy nội dung trong cột \"comment\"\n","\n","            # Xử lý Word segmentation trong tiếng Việt\n","            normalized_comment = ViTokenizer.tokenize(comment)\n","\n","            row[4] = normalized_comment  # Cập nhật nội dung đã chuẩn hóa vào cột \"comment\"\n","\n","            normalized_line = '\\t'.join(row)  # Ghép các cột thành dòng đã chuẩn hóa\n","\n","            normalized_lines.append(normalized_line)  # Thêm dòng đã chuẩn hóa vào danh sách\n","\n","    # Xuất kết quả ra file csv\n","    csv_file_path = '/content/gdrive/MyDrive/IE403/data_normalized.csv'  # Đường dẫn đến file csv\n","    with open(csv_file_path, 'w', newline='', encoding='utf-8') as file:\n","        writer = csv.writer(file, delimiter='\\t')\n","        writer.writerows([line.split('\\t') for line in normalized_lines])\n","\n","    # Xuất kết quả ra file txt\n","    txt_file_path = '/content/gdrive/MyDrive/IE403/data_normalized.txt'  # Đường dẫn đến file txt\n","    np.savetxt(txt_file_path, normalized_lines, fmt='%s', delimiter='\\t')\n","\n","# Ví dụ sử dụng hàm preprocess_text_file với một file có cột \"comment\"\n","preprocess_text_file(file_path1)"],"metadata":{"id":"cKbC-YY33FWO","executionInfo":{"status":"ok","timestamp":1684774872632,"user_tz":-420,"elapsed":1867,"user":{"displayName":"Nhân Nguyễn Thành","userId":"14305693631364031056"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RH8bw21o8tGF","executionInfo":{"status":"ok","timestamp":1684774872633,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nhân Nguyễn Thành","userId":"14305693631364031056"}}},"execution_count":11,"outputs":[]}]}